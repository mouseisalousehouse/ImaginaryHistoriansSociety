#+TITLE: Computation Mainframes in Early Deep Space Explorations

--------------------------

#+AUTHOR: by Raisha Xarex

=======================================================================

* Abstract

At the outset of the Second Exploration, there were four mainframe
computer assemblies capable of processing Starship Navigation Data
Packets (SNDaPs) at the scale required for dynamic variable hyperspace
calculations. These were: INIC, designed by Industrial Designs, Inc.,
Orion II, from Intex, and the AL-2900 and RL-320 Systems, from
Trepidatious Enterprises.

Exploration program directors were mandated immense
responsibility and had to make difficult choices about personnel,
resource managament, and technological progress. This essay argues
early decisions about deep space computation during the Second
Exploration had a tremendous effect upon starship capabilities in the
middle and late phases of the period. Ultimately, these early
technological choices were contributing factors in the decline and
collapse of space exploration during the era.

* Historical Background

3204.3 is generally considered to be the "start date" of the Second
Exploration. King Ozz III, of Naru-B, 

* Technical Background

Until the discovery of abstractspace by Ariel Moriarty in 5389[fn:1],
the only known reliable method of faster than light (FTL) travel was
to briefly pass into (or "skim") hyperspace with fusion
engines. Vessels would accelerate to near-light speeds (generally
between 0.8c and 0.85c) while advancing parallel to the plane of a
hyperspace fold. This allowed the vessel to briefly pass through
hyperspace, carrying the ship along the fold.[fn:2] Since hyperspace is wrapped around normal space (more precisely: since each point in hyperspace corresponds to two in normal space) 

This method of travel was cumbersome and costly. The vessels were very
large to accomodate the fusion engines, and were at the mercy of
hyperspace fold locations. The nearest hyperspace fold to Naru-B, home
of Ozz, is 3 light years away. During the entirety of the Second
Exploration, and well after, starships spent 4 years in deep space at
near-light before skimming hyperspace and completing their voyage.

Early forms of hyperspace skimming locked into a vector along the
hyperspace fold, and rode it until the fold passed away. This came to
be known as static variable hyperspace travel, because the trajectory
of the vessel relative to the fold-plane remained locked to the plane
itself. These calculations could be computed by humans, and were
suitable for A drawback of this kind of travel was
unpredictability--the hyperspace fold might spit a vessel out between
20 and 100 light years off course. This method of travel was unsuited
to deep space exploration because the distances

Dynamic Variable Hyperspace travel allowed the vessel to adjust its
relative trajectory to match the fold-plane, thereby giving the
navigator far more control over how far the fold would takt it.  The
calculations for this kind of travel are orders of magnitude more
complex. This complexity scaled with the mass of the vessel.

Computer mainframe assemblies were developed to make these
calculations. An array of radiotelescopes produced data about the relative location, and speed of the starship. SNDaPs were then fed into the mainframe assembly (either electronically or namually, as we will see), and the

 
* Footnotes

[fn:2] 

[fn:1]Moriarty, Ariel. "n-manifold Ryann Transformations Within Parallel Frames", 
